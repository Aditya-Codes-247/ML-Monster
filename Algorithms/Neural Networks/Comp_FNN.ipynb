{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Feed Forward Neural Network was written just for the sake of comparison for the Perceptron Post, and it may be removed or replaced in some other repository for better file structure of this Repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def init_wt():\n",
    "    return np.random.rand()\n",
    "\n",
    "def drelu(x):\n",
    "    return 1 if x > 0 else 0\n",
    "\n",
    "def mean_squared_error(predicted, actual):\n",
    "    return 0.5 * np.power(predicted - actual, 2)\n",
    "\n",
    "def shuffle(arr):\n",
    "    np.random.shuffle(arr)\n",
    "\n",
    "def evaluate_model(hidden_weights, hidden_layer_bias, output_weights, output_layer_bias, inputs, targets):\n",
    "    nHiddenNodes = hidden_weights.shape[1]\n",
    "    nOutNodes = output_weights.shape[1]\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for i in range(len(inputs)):\n",
    "        # Forward pass\n",
    "        hidden_layer = np.zeros(nHiddenNodes)\n",
    "        output_layer = np.zeros(nOutNodes)\n",
    "\n",
    "        for j in range(nHiddenNodes):\n",
    "            activation = hidden_layer_bias[j]\n",
    "            for k in range(inputs.shape[1]):\n",
    "                activation += inputs[i][k] * hidden_weights[k][j]\n",
    "            hidden_layer[j] = relu(activation)\n",
    "\n",
    "        for j in range(nOutNodes):\n",
    "            activation = output_layer_bias[j]\n",
    "            for k in range(nHiddenNodes):\n",
    "                activation += hidden_layer[k] * output_weights[k][j]\n",
    "            output_layer[j] = relu(activation)\n",
    "\n",
    "        loss = mean_squared_error(output_layer[0], targets[i][0])\n",
    "        total_loss += loss\n",
    "\n",
    "    average_loss = total_loss / len(inputs)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nInp = 2\n",
    "nHiddenNodes = 2\n",
    "nOutNodes = 1\n",
    "nTrainingSet = 4\n",
    "learning_rate = 0.001\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "epsilon = 1e-8\n",
    "hidden_layer = np.zeros(nHiddenNodes)\n",
    "output_layer = np.zeros(nOutNodes)\n",
    "\n",
    "hidden_layer_bias = np.zeros(nHiddenNodes)\n",
    "output_layer_bias = np.zeros(nOutNodes)\n",
    "\n",
    "hidden_weights = np.random.rand(nInp, nHiddenNodes)\n",
    "output_weights = np.random.rand(nHiddenNodes, nOutNodes)\n",
    "\n",
    "m_output = np.zeros((nHiddenNodes, nOutNodes))\n",
    "v_output = np.zeros((nHiddenNodes, nOutNodes))\n",
    "\n",
    "m_hidden = np.zeros((nInp, nHiddenNodes))\n",
    "v_hidden = np.zeros((nInp, nHiddenNodes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainign Inputs (OR Gate truth table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_inputs = np.array([[0.0, 0.0], [1.0, 0.0], [0.0, 1.0], [1.0, 1.0]])\n",
    "training_outputs = np.array([[0.0], [1.0], [1.0], [1.0]])\n",
    "\n",
    "trainingSetOrder = np.array([0, 1, 2, 3])\n",
    "numEpochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining, training and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Average Loss on Training Data: 0.033696591561024426\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(numEpochs):\n",
    "    shuffle(trainingSetOrder)\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for x in range(nTrainingSet):\n",
    "        i = trainingSetOrder[x]\n",
    "\n",
    "        # Forward pass\n",
    "        for j in range(nHiddenNodes):\n",
    "            activation = hidden_layer_bias[j]\n",
    "            for k in range(nInp):\n",
    "                activation += training_inputs[i][k] * hidden_weights[k][j]\n",
    "            hidden_layer[j] = relu(activation)\n",
    "\n",
    "        for j in range(nOutNodes):\n",
    "            activation = output_layer_bias[j]\n",
    "            for k in range(nHiddenNodes):\n",
    "                activation += hidden_layer[k] * output_weights[k][j]\n",
    "            output_layer[j] = relu(activation)\n",
    "\n",
    "        loss = mean_squared_error(output_layer[0], training_outputs[i][0])\n",
    "        total_loss += loss\n",
    "\n",
    "        # Backpropagation\n",
    "        deltaOutput = np.zeros(nOutNodes)\n",
    "        for j in range(nOutNodes):\n",
    "            error = training_outputs[i][j] - output_layer[j]\n",
    "            deltaOutput[j] = error * drelu(output_layer[j])\n",
    "\n",
    "        deltaHidden = np.zeros(nHiddenNodes)\n",
    "        for j in range(nHiddenNodes):\n",
    "            error = 0.0\n",
    "            for k in range(nOutNodes):\n",
    "                error += deltaOutput[k] * output_weights[j][k]\n",
    "            deltaHidden[j] = error * drelu(hidden_layer[j])\n",
    "\n",
    "        for j in range(nOutNodes):\n",
    "            for k in range(nHiddenNodes):\n",
    "                m_output[k][j] = beta1 * m_output[k][j] + (1 - beta1) * deltaOutput[j] * hidden_layer[k]\n",
    "                v_output[k][j] = beta2 * v_output[k][j] + (1 - beta2) * deltaOutput[j] * deltaOutput[j]\n",
    "                output_weights[k][j] += learning_rate * m_output[k][j] / (np.sqrt(v_output[k][j]) + epsilon)\n",
    "            output_layer_bias[j] += learning_rate * deltaOutput[j]\n",
    "\n",
    "        for j in range(nHiddenNodes):\n",
    "            for k in range(nInp):\n",
    "                m_hidden[k][j] = beta1 * m_hidden[k][j] + (1 - beta1) * deltaHidden[j] * training_inputs[i][k]\n",
    "                v_hidden[k][j] = beta2 * v_hidden[k][j] + (1 - beta2) * deltaHidden[j] * deltaHidden[j]\n",
    "                hidden_weights[k][j] += learning_rate * m_hidden[k][j] / (np.sqrt(v_hidden[k][j]) + epsilon)\n",
    "            hidden_layer_bias[j] += learning_rate * deltaHidden[j]\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch {epoch + 1}, Average Loss: {total_loss / nTrainingSet}\")\n",
    "\n",
    "# Evaluate the model\n",
    "average_loss = evaluate_model(hidden_weights, hidden_layer_bias, output_weights, output_layer_bias, training_inputs, training_outputs)\n",
    "print(f\"Final Average Loss on Training Data: {average_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
